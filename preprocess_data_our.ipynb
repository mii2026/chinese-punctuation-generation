{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root의 경우 ''안을 파일들이 들어있는 폴더의 경로로 변경합니다.\n",
    "# 만약 root 폴더가 D:\\chinese\\data/train3\\data인 경우, 해당 폴더 안은 아래에 첨부한 사진과 같은 형식으로 존재하게 해주시면 됩니다.\n",
    "# save_path의 경우 ''안에 전처리된 데이터를 저장할 파일의 이름을 정하여 작성해주시면 됩니다.\n",
    "# 경로를 지정해주시고, Preprocess data, Check preprocessed file 아래의 내용까지 돌려주시면 됩니다. (돌리고 싶은 칸을 누르고 shift+enter)\n",
    "\n",
    "root = 'D:\\chinese\\data/train3\\data'\n",
    "save_path = 'our_train3.txt' "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"folder.png\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "This is code for preprocessing data.\n",
    "You can preprocess data by excuting the code followed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from docx import Document\n",
    "import re\n",
    "import numpy as np\n",
    "from difflib import get_close_matches\n",
    "# Make the file list\n",
    "cleans = []\n",
    "puncs = []\n",
    "for i in os.listdir(root):\n",
    "    cleans = cleans + [os.path.join(root,i,'clean',j) for j in os.listdir(os.path.join(root, i, 'clean'))]\n",
    "    puncs = puncs + [os.path.join(root,i,'punc',j) for j in os.listdir(os.path.join(root, i, 'punc'))]\n",
    "assert len(cleans)==len(puncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(f):\n",
    "    # load file\n",
    "    text = Document(f)\n",
    "    data = ''\n",
    "    # remove title\n",
    "    i=0\n",
    "    while len(text.paragraphs[i].text) <=1:\n",
    "        i+=1\n",
    "    for j in text.paragraphs[i+1:]:\n",
    "        if len(j.text)>2:\n",
    "            data = data + j.text\n",
    "\n",
    "    # replace undefined punctuation to defined punctuation\n",
    "    data = data.replace(\"〈\", \"《\").replace(\"〉\", \"》\").replace('（', '(').replace('）',')').replace('+','')\n",
    "    data = data.replace('【','(').replace('】', ')').replace('[', '(').replace(']', ')').replace('〔', '(').replace('〕', ')')\n",
    "    data = data.replace('《 文摘报 》', '').replace('文摘报', '').replace('■', '').replace('/','').replace('~','').replace('●','')\n",
    "    data = data.replace(' ', '').replace('　', '').replace('\\u3000', '').replace('\\xa0', '').replace('\\n','')\n",
    "    data = data.replace('‘','“').replace('’','”').replace('？', '?').replace('！', '!').replace(\"，\", \",\").replace(\"：\", \":\").replace(\"；\", \";\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def change_format(t1, t2):\n",
    "    # compare clean file and punctuation file\n",
    "    # make the input and label\n",
    "    num = 0\n",
    "    while t1[0] != t2[num]:\n",
    "        num += 1\n",
    "    data = ''\n",
    "    for i in range(len(t1)):\n",
    "        data+=t1[i]+'\\t'\n",
    "        num+=1\n",
    "        if i == len(t1)-1:\n",
    "            data+=t2[num:]+'\\n'\n",
    "        elif t1[i+1] == t2[num]:\n",
    "            data+='O\\n'\n",
    "        else:\n",
    "            while t1[i+1] != t2[num]:\n",
    "                data+=t2[num]\n",
    "                num+=1\n",
    "            data+='\\n'\n",
    "\n",
    "    # remove () and inside\n",
    "    data = re.sub(pattern=r'O\\n\\([^)]*\\)\\t', repl='', string=data)\n",
    "    data = re.sub(pattern=r'\\n\\([^)]*\\)\\t', repl='', string=data)\n",
    "    data = re.sub(pattern=r'\\t\\([^)]*\\)\\n', repl='\\tO\\n', string=data)\n",
    "    data = re.sub(pattern=r'\\t\\([^)]*\\)', repl='\\t', string=data)\n",
    "    data = re.sub(pattern=r'\\([^)]*\\)\\n', repl='\\n', string=data)\n",
    "    data = re.sub(pattern=r'\\([^)]*\\)', repl='', string=data)\n",
    "    if data.find(')')>0:\n",
    "        data = data[data.find(')')+1:]\n",
    "        idx = data.index('\\n')\n",
    "        data = data[idx+1:]\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\chinese\\data/train3\\data\\200\\punc\\158.괏앎撚괏藤낀狼吝路懇끝방쪼.docx\n",
      "D:\\chinese\\data/train3\\data\\200\\punc\\200.櫓빽匡츠돨愷몸景醴.docx\n",
      "D:\\chinese\\data/train3\\data\\200\\punc\\36.“무列竟”呵혼懇끝 숨聯벌췽懃檄裂긴.docx\n",
      "D:\\chinese\\data/train3\\data\\200\\punc\\80.“5怯출옘쏵굇댕”，싱竿랙喇뎠쏴.docx\n",
      "D:\\chinese\\data/train3\\data\\500（1）\\punc\\134.벌소寮柩構쐤틱랙깊랗찖랗寧쾨劤쾨붕늦.docx\n",
      "D:\\chinese\\data/train3\\data\\500（1）\\punc\\165.構쐤틱瞳젬북벌膠뜩湳昑룟삔돨쉿뺐.docx\n",
      "D:\\chinese\\data/train3\\data\\500（1）\\punc\\217.벌소寮柩構쐤틱랙깊랗찖랗찖쾨劤쾨붕늦.docx\n",
      "D:\\chinese\\data/train3\\data\\500（1）\\punc\\221.構쐤틱밑黨《櫓묾櫓卵밑黨솽넣뵨供櫓벌景삔寮屢齡똑 股쏵벌소撈잿竟溝뵨撈잿콘제君덜뺏흼맴路댕狂痙돨엄땍》돨綱츠.docx\n",
      "D:\\chinese\\data/train3\\data\\500（1）\\punc\\245.構쐤틱瞳랗찖寧씽쾨뉴쌘考격삔돨쉿뺐.docx\n",
      "D:\\chinese\\data/train3\\data\\500（1）\\punc\\323.벌소寮柩構쐤틱랙깊랗찖寧펌쾨劤쾨붕늦.docx\n",
      "D:\\chinese\\data/train3\\data\\500（1）\\punc\\340.構쐤틱瞳欺構《빚쏩勍匡朞》괩멩삔돨쉿뺐（1）.docx\n",
      "D:\\chinese\\data/train3\\data\\500（1）\\punc\\341.構쐤틱瞳欺構《빚쏩勍匡朞》괩멩삔돨쉿뺐（2）.docx\n",
      "D:\\chinese\\data/train3\\data\\500（1）\\punc\\383.構쐤틱：瞳삔숨홍벌膽汲群官蝎션珂돨쉿뺐.docx\n",
      "D:\\chinese\\data/train3\\data\\500（1）\\punc\\394.벌소寮柩構쐤틱랙깊랗찖寧巧쾨劤쾨붕늦.docx\n",
      "D:\\chinese\\data/train3\\data\\500（1）\\punc\\40.構쐤틱：쏨쏨鍋훈솽넣뵨랙嵐櫓벌景삔寮屢 欺構忌눈밞낱뎨돨枷검댕쑹(4).docx\n",
      "D:\\chinese\\data/train3\\data\\500（1）\\punc\\436.벌소寮柩構쐤틱랙깊랗찖寧愷쾨劤쾨붕늦.docx\n",
      "D:\\chinese\\data/train3\\data\\500（1）\\punc\\438.瞳베북鱗莉廉냥逃벌禱看잿慤삔뒤枷힛늴삔累돨쉿뺐.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\102.됩鬼틱：茄慤헹角，角轟끓쌓섬各썹밖돨샘뇟.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\117.됩鬼틱：浬놔寧係櫓벌駕돨君덜뺏돛쨌.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\168.“행젭앙却”돨譚윱.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\169.建導：瞳轢쬠、菱伽宅뚤뺐裂쇌（1）.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\170.建導：瞳轢쬠、菱伽宅뚤뺐裂쇌（2）.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\171.建導：瞳轢쬠、菱伽宅뚤뺐裂쇌（3）.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\172.建導：瞳轢쬠、菱伽宅뚤뺐裂쇌（4）.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\173.建導：瞳轢쬠、菱伽宅뚤뺐裂쇌（5）.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\174.뼝磎솽련꿱.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\175.《鮫踏션》돨懃欺쓱썹.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\176.冀盜녑돨놓졔.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\180.췽痢考써寧소항돨匡欺깊댐.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\181.땜鮫：렷끽방잼깎宅櫂喇뺏깊댐.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\182.뻣寧蘆癩밟宅궝카돨저袈훙膠蝎畇.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\183.뮤쿰瞳쇌菱나.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\184.鹿궝카션쩌珂덜.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\185.헌츠쌘，뫄淪뮴훙윱寧끝蹴암댕濫걸！.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\187.부뇹角쉭굇.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\196.챘燈땜《쬠枷댕밑溝》돨쉿뺐.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\198.촙럴쟝：솽땍꼇盧浬櫓벌景썩엄췽痢狂痙돨攣횅돛쨌.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\210.샅科：힛槿뚜옘뮴宅櫓벌뮴袈눈넓竟溝(5).docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\27.綱慤、쉿잿宅쬠돛.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\31.匡츠팀송宅句롤契槨.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\32.君덜뺏잚謹欺、쌓뙈쬠宅櫓벌駕君덜뺏.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\66.됩鬼틱：밑폅쳔윱멥쉔角꼇契돨，랙嵐꼇폅윱.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\72.됩鬼틱：狼닒홍훙잚돨멕똑윱桔씩랙嵐狂痙.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\82.됩鬼틱：제헹겉離봤돨쑹稼존묽窘못훙췽.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\83.됩鬼틱：제헹겉離봤돨쑹稼존묽窘못훙췽.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\84.됩鬼틱：훙꼽꼇뙤淡君，乖쳬돨慤撚꼽唐句寡.docx\n",
      "D:\\chinese\\data/train3\\data\\500（2）\\punc\\90.됩鬼틱：乖쳬君瞳杰맴돨慤撚角寧淃劤慤撚.docx\n"
     ]
    }
   ],
   "source": [
    "f = open(save_path, 'w', encoding='utf-8')\n",
    "for i in puncs:\n",
    "    try:\n",
    "        clean = get_close_matches(i, cleans, 1, 0.9)\n",
    "        text1 = load_text(os.path.join(root, 'clean', clean[0]))\n",
    "        text2 = load_text(i)\n",
    "        f.write(change_format(text1, text2))\n",
    "    except Exception as e:        \n",
    "        print(i)\n",
    "        # 문장부호가 있는 파일과 없는 파일에서 형식이나 기호가 서로 다른 내용이 존재해 에러가 나오는 파일의 경우 제외하였습니다.\n",
    "        # 아래 나오는 파일명은 제외된 파일입니다.\n",
    "f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check preprocessed file\n",
    "Following code check the preprocessed file and fix the error.   \n",
    "If something that is not a punctuation mark appears, check the preprocessed file and correct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'《', '交', '·', '国', '方', '、', '电', '》', ')', '“', '美', '3', '1', '…', '?', 'O', ':', '陈', '创', '等', ';', '。', '，', '”', '研', '月', '!', '2', '—'}\n"
     ]
    }
   ],
   "source": [
    "f = open(save_path, 'r', encoding='utf-8') # preprocessed file path\n",
    "data = f.readlines()\n",
    "f.close()\n",
    "data2 = []\n",
    "for i in range(len(data)):\n",
    "    data[i] = data[i].replace('\\u3000', '').replace(' ', '').replace('  ', '').replace('\\xa0','').replace(\"\\u2003\", '')\n",
    "    data[i] = data[i].replace(',', '，').replace('......', '……').replace('.','。').replace('-', '—').replace(\"─\", '—').replace(\"一\", '—').replace('\"', 'O')\n",
    "    try:\n",
    "        if data[i].split('\\t')[1] == '\\n':\n",
    "            data[i] = data[i][:-1]+'O\\n'\n",
    "        data2.append(data[i])\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "punc = [i.split('\\t')[1][0] for i in data2]\n",
    "print(set(punc))\n",
    "\n",
    "f = open(save_path, \"w\", encoding='utf-8')\n",
    "for i in data2:\n",
    "    f.write(i.split('\\t')[0]+'\\t'+i.split('\\t')[1][0]+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기서 결과로 출력되는 것 중 문장 부호가 아닌 것은 직접 전처리 결과로 나온 파일에 들어가 수정해줍니다.\n",
    "# 전처리 파일은 현재 파일이 있는 폴더에 가장 상단에서 save_path에 작성한 이름으로 생성되었을 것입니다.\n",
    "# 전처리 파일을 보면, 왼쪽에 한자, 오른쪽에 문장부호 혹은 O가 존재하는데, 여기서 나온 한자나 사용하지 않는 문장부호를 O로 수정하였습니다.\n",
    "# 수정 후, 아래의 Count punc를 실행하시면 각 문장부호가 데이터에서 몇번 등장하는지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count punc\n",
    "Count the number of punctuation in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def count_punctuation(path):\n",
    "    f = open(path, 'r', encoding='utf-8')\n",
    "    data = f.readlines()\n",
    "    data = [i.split('\\t')[1][0] for i in data]\n",
    "    count = [data.count(','), data.count('。'), data.count('!'), data.count('?'), data.count(';'), data.count(':'), data.count('“'), data.count('”'),\n",
    "            data.count('…'), data.count('—'), data.count('、'), data.count('·'), data.count('《'), data.count('》')]\n",
    "    result = pd.DataFrame(\n",
    "        np.array([count]), \n",
    "        columns=list([',', '。', '!', '?', ';', ':', '“', '”', '…', '—', '、', '·', '《', '》']),\n",
    "        index = ['Count']\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,</th>\n",
       "      <th>。</th>\n",
       "      <th>!</th>\n",
       "      <th>?</th>\n",
       "      <th>;</th>\n",
       "      <th>:</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>…</th>\n",
       "      <th>—</th>\n",
       "      <th>、</th>\n",
       "      <th>·</th>\n",
       "      <th>《</th>\n",
       "      <th>》</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count</th>\n",
       "      <td>9040</td>\n",
       "      <td>3702</td>\n",
       "      <td>28</td>\n",
       "      <td>171</td>\n",
       "      <td>155</td>\n",
       "      <td>227</td>\n",
       "      <td>1041</td>\n",
       "      <td>1330</td>\n",
       "      <td>47</td>\n",
       "      <td>74</td>\n",
       "      <td>2246</td>\n",
       "      <td>41</td>\n",
       "      <td>304</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ,     。   !    ?    ;    :     “     ”   …   —     、   ·    《    》\n",
       "Count  9040  3702  28  171  155  227  1041  1330  47  74  2246  41  304  457"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'D:\\chinese_punctuation\\data\\our_test.txt'\n",
    "count_punctuation(path) # path to dataset what you want to count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chinese",
   "language": "python",
   "name": "chinese"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
