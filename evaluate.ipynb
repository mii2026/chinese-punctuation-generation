{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path of model\n",
    "- Change this to path of model you want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''안을 평가하시려는 모델의 파일 경로로 변경하고 아래 코드를 쭉 돌리시면 결과가 생성됩니다. (상단의 Run All 버튼을 눌러주세요.)\n",
    "# 학습하신 모델은 config.json 파일의 model_save_path로 지정하신 폴더 안에 생성되었습니다.\n",
    "# model_best의 경로를 넣고 측정하시면 됩니다.\n",
    "\n",
    "model_path = 'model/model_best'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import CNNLstmBert\n",
    "from data import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_size = 100\n",
    "output_size = 15\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNLstmBert(output_size).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dataloader, model, device):\n",
    "    puncs = [i for i in range(1, 15)]\n",
    "    with torch.no_grad():\n",
    "        y_preds = []\n",
    "        y_labels = []\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            _, output = model(inputs, device)\n",
    "            y_preds+=list(output.argmax(dim=1).cpu().data.numpy().flatten())\n",
    "            y_labels+=list(labels.cpu().data.numpy().flatten())\n",
    "    result = metrics.precision_recall_fscore_support(y_labels, y_preds, average=None, labels=puncs)\n",
    "    result = pd.DataFrame(np.array(result[:3]), columns=['，', '。', '！', '？', '；', '：', '“', '”', '…', '─', '、', '·', '《', '》'], index=['Precision', 'Recall', 'F1'])\n",
    "    result['Entire'] = metrics.precision_recall_fscore_support(y_labels, y_preds, average='macro',labels=puncs)[:3]\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on our testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 171606/171606 [00:06<00:00, 25070.31it/s]\n"
     ]
    }
   ],
   "source": [
    "testsets = []\n",
    "with open('data/our_test.txt', 'r', encoding='utf-8') as f:\n",
    "    test_data = f.readlines()\n",
    "testsets.append(test_data)\n",
    "testset = preprocessing(testsets, segment_size)\n",
    "testloader = DataLoader(testset, batch_size=200, shuffle=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:07<00:00,  1.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>，</th>\n",
       "      <th>。</th>\n",
       "      <th>！</th>\n",
       "      <th>？</th>\n",
       "      <th>；</th>\n",
       "      <th>：</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>…</th>\n",
       "      <th>─</th>\n",
       "      <th>、</th>\n",
       "      <th>·</th>\n",
       "      <th>《</th>\n",
       "      <th>》</th>\n",
       "      <th>Entire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.766602</td>\n",
       "      <td>0.682886</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.655340</td>\n",
       "      <td>0.190751</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.452693</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.750693</td>\n",
       "      <td>0.561204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.739544</td>\n",
       "      <td>0.769584</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.212903</td>\n",
       "      <td>0.533040</td>\n",
       "      <td>0.299038</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.774711</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.592998</td>\n",
       "      <td>0.451096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.752830</td>\n",
       "      <td>0.723647</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.716180</td>\n",
       "      <td>0.201220</td>\n",
       "      <td>0.502075</td>\n",
       "      <td>0.360162</td>\n",
       "      <td>0.360759</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.725605</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.662592</td>\n",
       "      <td>0.473909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ，         。         ！         ？         ；         ：  \\\n",
       "Precision  0.766602  0.682886  0.312500  0.655340  0.190751  0.474510   \n",
       "Recall     0.739544  0.769584  0.178571  0.789474  0.212903  0.533040   \n",
       "F1         0.752830  0.723647  0.227273  0.716180  0.201220  0.502075   \n",
       "\n",
       "                  “         ”         …         ─         、         ·  \\\n",
       "Precision  0.452693  0.452381  0.428571  0.250000  0.682353  1.000000   \n",
       "Recall     0.299038  0.300000  0.063830  0.013514  0.774711  0.390244   \n",
       "F1         0.360162  0.360759  0.111111  0.025641  0.725605  0.561404   \n",
       "\n",
       "                  《         》    Entire  \n",
       "Precision  0.757576  0.750693  0.561204  \n",
       "Recall     0.657895  0.592998  0.451096  \n",
       "F1         0.704225  0.662592  0.473909  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "our_result = evaluation(testloader, model, device)\n",
    "our_result\n",
    "\n",
    "# 아래 값이 저희가 생성한 테스트셋에서 모델을 평가한 결과입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on origin testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47965/47965 [00:01<00:00, 25005.59it/s]\n"
     ]
    }
   ],
   "source": [
    "testsets = []\n",
    "with open('data/test_iwslt.txt', 'r', encoding='utf-8') as f:\n",
    "    test_data = f.readlines()\n",
    "testsets.append(test_data)\n",
    "testset = preprocessing(testsets, segment_size)\n",
    "testloader = DataLoader(testset, batch_size=200, shuffle=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>，</th>\n",
       "      <th>。</th>\n",
       "      <th>！</th>\n",
       "      <th>？</th>\n",
       "      <th>；</th>\n",
       "      <th>：</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>…</th>\n",
       "      <th>─</th>\n",
       "      <th>、</th>\n",
       "      <th>·</th>\n",
       "      <th>《</th>\n",
       "      <th>》</th>\n",
       "      <th>Entire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.446095</td>\n",
       "      <td>0.356516</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182927</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256198</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.253454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.591779</td>\n",
       "      <td>0.591928</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.721088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.368229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.508712</td>\n",
       "      <td>0.445006</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223048</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.213018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353276</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.289306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ，         。         ！         ？    ；         ：         “  \\\n",
       "Precision  0.446095  0.356516  0.121212  0.683871  0.0  0.182927  0.243243   \n",
       "Recall     0.591779  0.591928  0.400000  0.721088  0.0  0.285714  0.391304   \n",
       "F1         0.508712  0.445006  0.186047  0.701987  0.0  0.223048  0.300000   \n",
       "\n",
       "                  ”    …    ─         、         ·         《         》  \\\n",
       "Precision  0.176471  0.0  0.0  0.256198  0.272727  0.400000  0.409091   \n",
       "Recall     0.268657  0.0  0.0  0.568807  0.666667  0.347826  0.321429   \n",
       "F1         0.213018  0.0  0.0  0.353276  0.387097  0.372093  0.360000   \n",
       "\n",
       "             Entire  \n",
       "Precision  0.253454  \n",
       "Recall     0.368229  \n",
       "F1         0.289306  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "iwslt_result = evaluation(testloader, model, device)\n",
    "iwslt_result\n",
    "# 아래 값이 저희가 iwslt2012 테스트셋에서 모델을 평가한 결과입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chinese",
   "language": "python",
   "name": "chinese"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b28182bba776836eeb93f14c07a53f4592db97e4f406f04c850052e736c03e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
